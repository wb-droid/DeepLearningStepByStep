{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d8b323-5d33-439f-b82d-4bb3505d7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor \n",
    "from transformers import BertModel, BertTokenizer\n",
    "import gzip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb5ef35-7485-420b-958f-45fc8c55683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, bertName = \"bert-base-uncased\"): # other bert models can also be supported\n",
    "        super().__init__()\n",
    "        self.bertName = bertName\n",
    "        # use BERT model\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bertName)\n",
    "        self.model = BertModel.from_pretrained(self.bertName)        \n",
    "       \n",
    "    def forward(self, s, device = \"cuda\"):\n",
    "        # get tokens, which also include attention_mask\n",
    "        tokens = self.tokenizer(s, return_tensors='pt', padding = \"max_length\", truncation = True, max_length = 256).to(device)\n",
    "        \n",
    "        # get token embeddings\n",
    "        output = self.model(**tokens)\n",
    "        tokens_embeddings = output.last_hidden_state\n",
    "        #print(\"tokens_embeddings:\" + str(tokens_embeddings.shape))\n",
    "        \n",
    "        # mean pooling to get text embedding\n",
    "        embeddings = tokens_embeddings * tokens.attention_mask[...,None] # [B, T, emb]\n",
    "        #print(\"embeddings:\" + str(embeddings.shape))\n",
    "        \n",
    "        embeddings = embeddings.sum(1) # [B, emb]\n",
    "        valid_tokens = tokens.attention_mask.sum(1) # [B]\n",
    "        embeddings = embeddings / valid_tokens[...,None] # [B, emb]    \n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    # from scratch: nn.CosineSimilarity(dim = 1)(q,a)\n",
    "    def cos_score(self, q, a): \n",
    "        q_norm = q / (q.pow(2).sum(dim=1, keepdim=True).pow(0.5))\n",
    "        r_norm = a / (a.pow(2).sum(dim=1, keepdim=True).pow(0.5))\n",
    "        return (q_norm @ r_norm.T).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdb06ed-3d47-46e4-a675-e990b22c298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrastive training\n",
    "class TrainModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m = EmbeddingModel(\"bert-base-uncased\")\n",
    "\n",
    "    def forward(self, s1, s2, score):        \n",
    "        cos_score = self.m.cos_score(self.m(s1), self.m(s2))\n",
    "        loss = nn.MSELoss()(cos_score, score)\n",
    "        return loss, cos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110849fc-d441-47fb-b0f1-e2a1e0bdf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_load=torch.load(\"myTextEmbedding.pt\")\n",
    "m=training_load.m\n",
    "#m = EmbeddingModel().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b80a8a3-e3f2-4302-b2d5-a90dc073d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e12c1b-0a92-4cef-aa99-bc7d495c4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchWiki(s):\n",
    "    response = requests.get(\n",
    "            'https://en.wikipedia.org/w/api.php',\n",
    "            params={\n",
    "                'action': 'query',\n",
    "                'format': 'json',\n",
    "                'titles': s,\n",
    "                'prop': 'extracts',\n",
    "                'exintro': True,\n",
    "                'explaintext': True,\n",
    "            }\n",
    "        ).json()\n",
    "    page = next(iter(response['query']['pages'].values()))\n",
    "    return page['extract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a37fdf3-7c2e-46b3-af7a-4dd0cd463853",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = [\"vector database\", \"Similarity search\", \"Sentence embedding\"]\n",
    "wiki_data = [searchWiki(c).replace(\"\\n\",\"\") for c in concepts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07846fcf-71a0-44ad-bf38-21960daed55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 256 # as EmbeddingModel default context length, i.e.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1751d0f-cff4-4825-a753-8f330a0cfe29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A vector database management system (VDBMS) or simply vector database or vector store is a database that can store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more Approximate Nearest Nei',\n",
       " 'ghbor (ANN) algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.Vectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a f',\n",
       " \"eature of the data, with the number of dimensions ranging from few hundreds to tens of thousands, depending on the complexity of the data being represented. A vector's position in this space represents its characteristics. Words, phrases, or entire documen\",\n",
       " 'ts, and images, audio, and other types of data can all be vectorized. These feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that ',\n",
       " 'semantically similar data items receive feature vectors that are close to each other. Vector databases can be used for similarity search, multi-modal search, recommendations engines, large language models (LLMs), etc.Vector databases are also used to imple',\n",
       " 'ment Retrieval-Augmented Generation (RAG), a method to improve domain-specific responses of large language models. Text documents describing the domain of interest are collected and for each document a feature vector (known as an \"embedding\") is computed, ',\n",
       " 'typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed and the database is queried to retrieve the most relevant documents. These are then automatically added into the con',\n",
       " 'text window of the large language model and the large language model proceeds to create a response to the prompt given this context.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixed size chunking\n",
    "def chunk(w):\n",
    "    return [w[i:i+chunk_size] for i in range(0,len(w),chunk_size)]\n",
    "chunk(wiki_data[0])        \n",
    "#len(wiki_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad65e249-3736-4981-9eff-b61d71010d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A vector database management system (VDBMS) or simply vector database or vector store is a database that can store vectors (fixed-length lists of numbers) along with other data items',\n",
       " ' Vector databases typically implement one or more Approximate Nearest Neighbor (ANN) algorithms, so that one can search the database with a query vector to retrieve the closest matching database records',\n",
       " 'Vectors are mathematical representations of data in a high-dimensional space',\n",
       " ' In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from few hundreds to tens of thousands, depending on the complexity of the data being represented',\n",
       " \" A vector's position in this space represents its characteristics\",\n",
       " ' Words, phrases, or entire documents, and images, audio, and other types of data can all be vectorized',\n",
       " ' These feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks',\n",
       " ' The goal is that semantically similar data items receive feature vectors that are close to each other',\n",
       " ' Vector databases can be used for similarity search, multi-modal search, recommendations engines, large language models (LLMs), etc',\n",
       " 'Vector databases are also used to implement Retrieval-Augmented Generation (RAG), a method to improve domain-specific responses of large language models',\n",
       " ' Text documents describing the domain of interest are collected and for each document a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database',\n",
       " ' Given a user prompt, the feature vector of the prompt is computed and the database is queried to retrieve the most relevant documents',\n",
       " ' These are then automatically added into the context window of the large language model and the large language model proceeds to create a response to the prompt given this context',\n",
       " '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentense chunking\n",
    "def chunk(w):\n",
    "    return w.split(\".\")\n",
    "chunk(wiki_data[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6a3723-83c9-4b43-9629-9dbe8e41d34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A vector database management system (VDBMS) or simply vector database or vector store is a database that can store vectors (fixed-length lists of numbers) along with other data items.',\n",
       " 'Vector databases typically implement one or more Approximate Nearest Neighbor (ANN) algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.',\n",
       " 'Vectors are mathematical representations of data in a high-dimensional space.',\n",
       " 'In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from few hundreds to tens of thousands, depending on the complexity of the data being represented.',\n",
       " \"A vector's position in this space represents its characteristics.\",\n",
       " 'Words, phrases, or entire documents, and images, audio, and other types of data can all be vectorized.',\n",
       " 'These feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks.',\n",
       " 'The goal is that semantically similar data items receive feature vectors that are close to each other.',\n",
       " 'Vector databases can be used for similarity search, multi-modal search, recommendations engines, large language models (LLMs), etc.',\n",
       " 'Vector databases are also used to implement Retrieval-Augmented Generation (RAG), a method to improve domain-specific responses of large language models.',\n",
       " 'Text documents describing the domain of interest are collected and for each document a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database.',\n",
       " 'Given a user prompt, the feature vector of the prompt is computed and the database is queried to retrieve the most relevant documents.',\n",
       " 'These are then automatically added into the context window of the large language model and the large language model proceeds to create a response to the prompt given this context.',\n",
       " 'Similarity search is the most general term used for a range of mechanisms which share the principle of searching (typically very large) spaces of objects where the only available comparator is the similarity between any pair of objects.',\n",
       " 'This is becoming increasingly important in an age of large information repositories where the objects contained do not possess any natural order, for example large collections of images, sounds and other sophisticated digital objects.',\n",
       " 'Nearest neighbor search and range queries are important subclasses of similarity search, and a number of solutions exist.',\n",
       " 'Research in similarity search is dominated by the inherent problems of searching over complex objects.',\n",
       " 'Such objects cause most known techniques to lose traction over large collections, due to a manifestation of the  so-called  curse of dimensionality, and there are still many unsolved problems.',\n",
       " 'Unfortunately, in many cases where similarity search is necessary, the objects are inherently complex.',\n",
       " 'The most general approach to similarity search relies upon the mathematical notion of metric space, which allows the construction of efficient index structures in order to achieve scalability in the search domain.',\n",
       " 'Similarity search evolved independently in a number of different scientific and computing contexts, according to various needs.',\n",
       " 'In 2008 a few leading researchers in the field felt strongly that the subject should be a research topic in its own right, to allow focus on the general issues applicable across the many diverse domains of its use.',\n",
       " 'This resulted in the formation of the SISAP foundation, whose main activity is a series of annual international conferences on the generic topic.',\n",
       " 'In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.',\n",
       " 'State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models.',\n",
       " 'BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks.',\n",
       " \"In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings.\",\n",
       " \"SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset.\",\n",
       " 'Other approaches are loosely based on the idea of distributional semantics applied to sentences.',\n",
       " 'Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions.',\n",
       " 'Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT.',\n",
       " 'An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings.',\n",
       " 'The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW).',\n",
       " 'However, more elaborate solutions based on word vector quantization have also been proposed.',\n",
       " 'One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_data = []\n",
    "for w in wiki_data:\n",
    "    chunk_data = chunk_data + chunk(w) \n",
    "\n",
    "chunk_data = [c.strip()+\".\" for c in chunk_data]\n",
    "while '.' in chunk_data:\n",
    "    chunk_data.remove('.')\n",
    "chunk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "852a8bf6-c6e3-491e-bb63-bc3c0e53849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_emb = m(chunk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1688a1f-65c5-4743-b159-bf29b1644d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = [\"what is embedding\"]\n",
    "result_score = m.cos_score(m(question).expand(chunk_emb.shape),chunk_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e61e3d0-73c8-458b-84ba-4ea00efd53a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74dce935-335b-4fb3-b8e8-0e2d104433a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(question).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "802912c6-edeb-4d95-bb09-b7d81821ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,idxs = torch.topk(result_score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c572f7b8-fe1b-48a9-a33c-b77fc64635eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4591, 0.5320, 0.5176, 0.5351, 0.5761, 0.5203, 0.5421, 0.5658, 0.5095,\n",
       "        0.5275, 0.5734, 0.5198, 0.5224, 0.5555, 0.5569, 0.5305, 0.6105, 0.5481,\n",
       "        0.5712, 0.5381, 0.4875, 0.5586, 0.5119, 0.5479, 0.6304, 0.5918, 0.5842,\n",
       "        0.5537, 0.6217, 0.6240, 0.5312, 0.5952, 0.5661, 0.5491, 0.5608],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_score.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cb1917d-e4e2-4ec1-b3fd-41dad31dfe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4386, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_score.flatten()[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e64812c7-31c0-4c9a-a62c-f2de41f5932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 31, 27]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d55e6668-75aa-460a-9125-0edc51ba4ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models.',\n",
       " 'An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings.',\n",
       " \"SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset.\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[chunk_data[idx] for idx in idxs.flatten().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0840bbab-3224-4972-8987-b2ded46779aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models.',\n",
       " 'Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions.',\n",
       " 'Other approaches are loosely based on the idea of distributional semantics applied to sentences.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[chunk_data[idx] for idx in idxs.flatten().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ad8b897-62c8-4799-850a-2066023fa526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_document(s, topk=3):\n",
    "    question = [s]\n",
    "    result_score = m.cos_score(m(question).expand(chunk_emb.shape),chunk_emb)\n",
    "    print(result_score)\n",
    "    _,idxs = torch.topk(result_score,topk)\n",
    "    print([result_score.flatten()[idx] for idx in idxs.flatten().tolist()])\n",
    "    return [chunk_data[idx] for idx in idxs.flatten().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6baa6518-50d4-415e-bb4c-8c6caa253685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1173, 0.1579, 0.1608, 0.2874, 0.1524, 0.2882, 0.3161, 0.2539, 0.1580,\n",
      "        0.2775, 0.3162, 0.1425, 0.2240, 0.2439, 0.3948, 0.2428, 0.1651, 0.3433,\n",
      "        0.2615, 0.1924, 0.2228, 0.1930, 0.1392, 0.2549, 0.5884, 0.2730, 0.2193,\n",
      "        0.3320, 0.3042, 0.2103, 0.3500, 0.3279, 0.1144, 0.3512, 0.3090],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0>)\n",
      "[tensor(0.5884, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.3948, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.3512, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models.',\n",
       " 'This is becoming increasingly important in an age of large information repositories where the objects contained do not possess any natural order, for example large collections of images, sounds and other sophisticated digital objects.',\n",
       " 'However, more elaborate solutions based on word vector quantization have also been proposed.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"what are State of the art embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab72625a-208f-48e5-ab8a-37eb5eb02e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.7679, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.6845, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.6748, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models.',\n",
       " 'This is becoming increasingly important in an age of large information repositories where the objects contained do not possess any natural order, for example large collections of images, sounds and other sophisticated digital objects.',\n",
       " 'Text documents describing the domain of interest are collected and for each document a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"what are State of the art embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "328b229d-9f06-47cb-a0a6-b7f9c4f4cfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0689,  0.0256,  0.1134,  0.1077,  0.1104,  0.1202, -0.0071,  0.1059,\n",
      "         0.1150,  0.0014,  0.0659,  0.0246,  0.0981,  0.1139,  0.0393,  0.0760,\n",
      "         0.0595,  0.0616,  0.0125,  0.0545,  0.0927,  0.1908,  0.5429,  0.1074,\n",
      "         0.0997,  0.1076,  0.1373,  0.1768,  0.1730,  0.1053,  0.1760,  0.1794,\n",
      "         0.0870,  0.0704,  0.1369], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0>)\n",
      "[tensor(0.5429, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.1908, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.1794, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This resulted in the formation of the SISAP foundation, whose main activity is a series of annual international conferences on the generic topic.',\n",
       " 'In 2008 a few leading researchers in the field felt strongly that the subject should be a research topic in its own right, to allow focus on the general issues applicable across the many diverse domains of its use.',\n",
       " 'An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"what is SISAP foundation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1554dddf-e0f3-4b80-ad7d-71ecfac980e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.5501, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.5260, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.5019, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This resulted in the formation of the SISAP foundation, whose main activity is a series of annual international conferences on the generic topic.',\n",
       " 'Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions.',\n",
       " 'In 2008 a few leading researchers in the field felt strongly that the subject should be a research topic in its own right, to allow focus on the general issues applicable across the many diverse domains of its use.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"what is SISAP foundation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3b339bc-063e-4e79-952d-82d86f0964a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2074, 0.1640, 0.2663, 0.2546, 0.1525, 0.5036, 0.4202, 0.4270, 0.3133,\n",
      "        0.2790, 0.3995, 0.2420, 0.4209, 0.3161, 0.2915, 0.2927, 0.2304, 0.1892,\n",
      "        0.2789, 0.2547, 0.2093, 0.1940, 0.1916, 0.6079, 0.5657, 0.4848, 0.3760,\n",
      "        0.4391, 0.6059, 0.5217, 0.1623, 0.7555, 0.2698, 0.4316, 0.4551],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0>)\n",
      "[tensor(0.7555, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.6079, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.6059, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings.',\n",
       " 'In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.',\n",
       " 'Other approaches are loosely based on the idea of distributional semantics applied to sentences.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"what are sentence embeddings?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca049007-0891-4212-8cf6-d36c99056085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.7916, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.7334, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.7326, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings.',\n",
       " 'In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.',\n",
       " 'Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"what are sentence embeddings?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "810c56f2-6ced-4c93-8482-deab64b37fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1262, 0.0500, 0.1203, 0.1252, 0.1615, 0.1370, 0.0351, 0.0883, 0.0687,\n",
      "        0.0639, 0.0649, 0.0890, 0.0863, 0.0819, 0.0777, 0.1128, 0.0566, 0.1082,\n",
      "        0.1061, 0.0951, 0.0455, 0.0086, 0.0588, 0.1971, 0.0516, 0.3951, 0.4957,\n",
      "        0.3823, 0.1412, 0.1151, 0.1914, 0.1348, 0.1328, 0.1268, 0.0983],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0>)\n",
      "[tensor(0.4957, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.3951, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.3823, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings.\",\n",
       " 'BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks.',\n",
       " \"SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset.\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"what is BERT?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56527793-d2f9-48d4-84e0-0de5de79aaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2179, 0.5065, 0.1234, 0.2750, 0.2229, 0.1145, 0.2659, 0.3370, 0.3362,\n",
      "        0.2488, 0.2640, 0.2444, 0.1571, 0.4875, 0.2580, 0.5563, 0.4745, 0.2181,\n",
      "        0.3890, 0.4118, 0.3547, 0.1441, 0.1433, 0.1586, 0.1362, 0.1867, 0.2015,\n",
      "        0.1898, 0.1985, 0.1981, 0.1363, 0.1715, 0.2007, 0.2436, 0.1812],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0>)\n",
      "[tensor(0.5563, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.5065, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.4875, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Nearest neighbor search and range queries are important subclasses of similarity search, and a number of solutions exist.',\n",
       " 'Vector databases typically implement one or more Approximate Nearest Neighbor (ANN) algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.',\n",
       " 'Similarity search is the most general term used for a range of mechanisms which share the principle of searching (typically very large) spaces of objects where the only available comparator is the similarity between any pair of objects.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"what is Nearest neighbor search?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf87f365-6248-423f-b316-1e3e3656ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3254, 0.5237, 0.2649, 0.3176, 0.2846, 0.2579, 0.3631, 0.4937, 0.5642,\n",
      "        0.3998, 0.3535, 0.3247, 0.1850, 0.6416, 0.2925, 0.5873, 0.6323, 0.2343,\n",
      "        0.5752, 0.5734, 0.5358, 0.2268, 0.1483, 0.2711, 0.1813, 0.2128, 0.1444,\n",
      "        0.2308, 0.2644, 0.2422, 0.1182, 0.2163, 0.2448, 0.2656, 0.2814],\n",
      "       device='cuda:0', grad_fn=<DiagonalBackward0>)\n",
      "[tensor(0.6416, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.6323, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.5873, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Similarity search is the most general term used for a range of mechanisms which share the principle of searching (typically very large) spaces of objects where the only available comparator is the similarity between any pair of objects.',\n",
       " 'Research in similarity search is dominated by the inherent problems of searching over complex objects.',\n",
       " 'Nearest neighbor search and range queries are important subclasses of similarity search, and a number of solutions exist.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_document(\"how to do similarity search?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4f9f4-b369-4d72-b1b9-4ce06956d8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
