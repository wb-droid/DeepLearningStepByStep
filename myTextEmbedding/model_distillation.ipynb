{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e95a9c3-40a3-4db9-bc69-3e15a61d2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# https://github.com/UKPLab/sentence-transformers/tree/master/examples/training/distillation\n",
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/distillation/model_distillation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac440cfc-aaae-43b9-bb57-72b5b16b14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myTextEmbedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc378666-7432-43f1-a6a3-ec6a5eb09e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the knowledge database\n",
    "chunk_data = generate_chunk_data([\"AI\",\"moon\",\"brain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887cc890-d528-4fc3-a899-b5a7e2d864b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Moon is Earth's only natural satellite.\",\n",
       " 'It orbits at an average distance of 384,400 km (238,900 mi), about 30 times the diameter of Earth.',\n",
       " \"Over time Earth's gravity has caused tidal locking, causing the same side of the Moon to always face Earth.\",\n",
       " 'Because of this, the lunar day and the lunar month are the same length, at 29.',\n",
       " '5 Earth days.',\n",
       " \"The Moon's gravitational pull – and to a lesser extent, the Sun's – are the main drivers of Earth's tides.\",\n",
       " 'In geophysical terms the Moon is a planetary-mass object or satellite planet.',\n",
       " 'Its mass is 1.',\n",
       " \"2% that of the Earth, and its diameter is 3,474 km (2,159 mi), roughly one-quarter of Earth's (about as wide as Australia.\",\n",
       " ') Within the Solar System, it is the largest and most massive satellite in relation to its parent planet, the fifth largest and most massive moon overall, and larger and more massive than all known dwarf planets.',\n",
       " \"Its surface gravity is about one sixth of Earth's, about half of that of Mars, and the second highest among all Solar System moons, after Jupiter's moon Io.\",\n",
       " 'The body of the Moon is differentiated and terrestrial, with no significant hydrosphere, atmosphere, or magnetic field.',\n",
       " 'It formed 4.',\n",
       " \"51 billion years ago, not long after Earth's formation, out of the debris from a giant impact between Earth and a hypothesized Mars-sized body called Theia.\",\n",
       " 'The lunar surface is covered in lunar dust and marked by mountains, impact craters, their ejecta, ray-like streaks and, mostly on the near side of the Moon, by dark maria (\"seas\"), which are plains of cooled magma.',\n",
       " 'These maria were formed when molten lava flowed into ancient impact basins.',\n",
       " \"The Moon is, except when passing through Earth's shadow during a lunar eclipse, always illuminated by the Sun, but from Earth the visible illumination shifts during its orbit, producing the lunar phases.\",\n",
       " \"The Moon is the brightest celestial object in Earth's night sky.\",\n",
       " 'This is mainly due to its large angular diameter, while the reflectance of the lunar surface is comparable to that of asphalt.',\n",
       " 'The apparent size is nearly the same as that of the Sun, allowing it to cover the Sun completely during a total solar eclipse.',\n",
       " 'From Earth about 59% of the lunar surface is visible over time due to cyclical shifts in perspective (libration), making parts of the far side of the Moon visible.',\n",
       " 'For humans the Moon has been an important source of inspiration and knowledge, having been crucial to cosmography, mythology, religion, art, time keeping, natural science, and spaceflight.',\n",
       " \"On September 13, 1959, the first human-made object to reach an extraterrestrial body arrived on the Moon, the Soviet Union's Luna 2 impactor.\",\n",
       " 'In 1966, the Moon became the first extraterrestrial body where soft landings and orbital insertions were achieved.',\n",
       " \"On July 20, 1969, humans for the first time landed on the Moon and any extraterrestrial body, at Mare Tranquillitatis with the lander Eagle of the United States' Apollo 11 mission.\",\n",
       " 'Five more crews were sent between then and 1972, each with two men landing on the surface.',\n",
       " 'The longest stay was 75 hours by the Apollo 17 crew.',\n",
       " 'Since then, exploration of the Moon has continued robotically with crewed missions being planned to return beginning in the late 2020s.',\n",
       " 'The brain is an organ that serves as the center of the nervous system in all vertebrate and most invertebrate animals.',\n",
       " 'In vertebrates, a small part of the brain called the hypothalamus is the neural control center for all endocrine systems.',\n",
       " 'The brain is the largest cluster of neurons in the body and is typically located in the head, usually near organs for special senses such as vision, hearing and olfaction.',\n",
       " 'It is the most energy-consuming organ of the body, and the most specialized, responsible for endocrine regulation, sensory perception, motor control, and the development of intelligence.',\n",
       " 'While invertebrate brains arise from paired segmental ganglia (each of which is only responsible for the respective body segment) of the ventral nerve cord, vertebrate brains develop axially from the midline dorsal nerve cord as a vesicular enlargement at the rostral end of the neural tube, with centralized control over all body segments.',\n",
       " 'All vertebrate brains can be embryonically divided into three parts: the forebrain (prosencephalon, subdivided into telencephalon and diencephalon), midbrain (mesencephalon) and hindbrain (rhombencephalon, subdivided into metencephalon and myelencephalon).',\n",
       " 'The spinal cord, which directly interacts with somatic functions below the head, can be considered a caudal extension of the myelencephalon enclosed inside the vertebral column.',\n",
       " 'Together, the brain and spinal cord constitute the central nervous system in all vertebrates.',\n",
       " 'In humans, the cerebral cortex contains approximately 14–16 billion neurons, and the estimated number of neurons in the cerebellum is 55–70 billion.',\n",
       " 'Each neuron is connected by synapses to several thousand other neurons, typically communicating with one another via root-like protrusions called dendrites and long fiber-like extensions called axons, which are usually myelinated and carry trains of rapid micro-electric signal pulses called action potentials to target specific recipient cells in other areas of the brain or distant parts of the body.',\n",
       " 'The prefrontal cortex, which controls executive functions, is particularly well developed in humans.',\n",
       " \"Physiologically, brains exert centralized control over a body's other organs.\",\n",
       " 'They act on the rest of the body both by generating patterns of muscle activity and by driving the secretion of chemicals called hormones.',\n",
       " 'This centralized control allows rapid and coordinated responses to changes in the environment.',\n",
       " 'Some basic types of responsiveness such as reflexes can be mediated by the spinal cord or peripheral ganglia, but sophisticated purposeful control of behavior based on complex sensory input requires the information integrating capabilities of a centralized brain.',\n",
       " 'The operations of individual brain cells are now understood in considerable detail but the way they cooperate in ensembles of millions is yet to be solved.',\n",
       " 'Recent models in modern neuroscience treat the brain as a biological computer, very different in mechanism from a digital computer, but similar in the sense that it acquires information from the surrounding world, stores it, and processes it in a variety of ways.',\n",
       " 'This article compares the properties of brains across the entire range of animal species, with the greatest attention to vertebrates.',\n",
       " 'It deals with the human brain insofar as it shares the properties of other brains.',\n",
       " 'The ways in which the human brain differs from other brains are covered in the human brain article.',\n",
       " 'Several topics that might be covered here are instead covered there because much more can be said about them in a human context.',\n",
       " 'The most important that are covered in the human brain article are brain disease and the effects of brain damage.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e69717-eb31-4a08-a97a-ac28ae46fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_load=torch.load(\"myTextEmbedding.pt\").to(\"cpu\")\n",
    "m=training_load.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "434c160f-b448-48fd-968a-cd708d0c694c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingModel(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above is for teacher model and teacher embedding\n",
    "# The next is to create student model\n",
    "# EmbeddingModel's encoder has 12 BertLayers, to reduce to 6.\n",
    "student_model = EmbeddingModel()\n",
    "student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ba34fd-d00a-4288-9ac6-da0f8a8f16d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-11): 12 x BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.model.encoder.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461b81e0-3c0e-4a13-b234-48537973c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-5): 6 x BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers to keep out of the 12 BertLayers in encoder\n",
    "layers_to_keep = [0,2,4,6,8,11]\n",
    "\n",
    "# remove the rest layers\n",
    "new_layers = nn.ModuleList([layer for i, layer in enumerate(student_model.model.encoder.layer) if i in layers_to_keep])\n",
    "new_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7502b5d9-d1c7-4732-87ba-3080e8f1ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.model.encoder.layer = new_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f55e7c-16b4-48d8-a7b2-0dee5144f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the student training model\n",
    "class TrainStudent(nn.Module):\n",
    "    def __init__(self, student_model):\n",
    "        super().__init__()\n",
    "        self.student_model = student_model\n",
    "\n",
    "    def forward(self, s1, teacher_model):\n",
    "        emb_student = self.student_model(s1)\n",
    "        emb_teacher = teacher_model(s1)\n",
    "        mse = (emb_student - emb_teacher).pow(2).mean()\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73508ff-27ee-4444-a0ec-cf5b886e006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same sts data for training\n",
    "df = pd.read_csv(\"stsbenchmark.tsv\", delimiter=\"\\t\", low_memory = False, on_bad_lines = 'skip',  skiprows=[8300])\n",
    "df = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e47a4b0-af14-42bd-9f21-417845a87ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentence\"] = df[\"sentence1\"] + df[\"sentence2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7229852c-2d00-40f6-8adc-40a27d144ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>genre</th>\n",
       "      <th>dataset</th>\n",
       "      <th>year</th>\n",
       "      <th>sid</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>A plane is taking off.An air plane is taking off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>4</td>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>A man is playing a large flute.A man is playin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>5</td>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>6</td>\n",
       "      <td>2.60</td>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "      <td>Three men are playing chess.Two men are playin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>9</td>\n",
       "      <td>4.25</td>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "      <td>A man is playing the cello.A man seated is pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split          genre dataset      year  sid  score  \\\n",
       "0  train  main-captions  MSRvid  2012test    1   5.00   \n",
       "1  train  main-captions  MSRvid  2012test    4   3.80   \n",
       "2  train  main-captions  MSRvid  2012test    5   3.80   \n",
       "3  train  main-captions  MSRvid  2012test    6   2.60   \n",
       "4  train  main-captions  MSRvid  2012test    9   4.25   \n",
       "\n",
       "                                       sentence1  \\\n",
       "0                         A plane is taking off.   \n",
       "1                A man is playing a large flute.   \n",
       "2  A man is spreading shreded cheese on a pizza.   \n",
       "3                   Three men are playing chess.   \n",
       "4                    A man is playing the cello.   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0                        An air plane is taking off.   \n",
       "1                          A man is playing a flute.   \n",
       "2  A man is spreading shredded cheese on an uncoo...   \n",
       "3                         Two men are playing chess.   \n",
       "4                 A man seated is playing the cello.   \n",
       "\n",
       "                                            sentence  \n",
       "0  A plane is taking off.An air plane is taking off.  \n",
       "1  A man is playing a large flute.A man is playin...  \n",
       "2  A man is spreading shreded cheese on a pizza.A...  \n",
       "3  Three men are playing chess.Two men are playin...  \n",
       "4  A man is playing the cello.A man seated is pla...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e93e24c-aec4-4fe2-b6b8-6cca9eb9838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5703, 1463, 1116)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['split']=='train']\n",
    "df_eval = df[df['split']=='dev']\n",
    "df_test = df[df['split']=='test']\n",
    "len(df_train), len(df_eval), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89eab18b-2dad-4acf-8b26-a7c92cbde70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_student = TrainStudent(student_model).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30849494-650f-4b19-8fd0-cfeebc1062fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d692ec-28fa-4975-986d-2eb1ea24c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=torch.load(\"myTextEmbedding.pt\").m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ad81251-6b5e-42e8-984c-bb0f813d3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(training = True):\n",
    "    if training == True:\n",
    "        optimizer = torch.optim.AdamW(train_student.parameters(), lr=1e-5)\n",
    "    losses = 0\n",
    "    losses_eval = 0\n",
    "    for i in range(0,len(df_train),batch_size):\n",
    "        #if training == True:\n",
    "        if 1:\n",
    "            train_student.train()\n",
    "            batch = df_train.iloc[i:i+batch_size]\n",
    "            \n",
    "            loss = train_student(list(batch['sentence']), m )\n",
    "            losses += loss\n",
    "        \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()   \n",
    "        \n",
    "        #else:\n",
    "            train_student.eval()\n",
    "            ieval = i % len(df_eval)\n",
    "            batch = df_eval.iloc[ieval:ieval+batch_size]\n",
    "            with torch.no_grad():\n",
    "                loss = train_student(list(batch['sentence']), m )\n",
    "            losses_eval += loss\n",
    "            \n",
    "        if (i % 200 == 0):\n",
    "            print(f'batch {i}, loss {losses/200} eval {losses_eval/200}')\n",
    "            losses = 0\n",
    "            losses_eval = 0\n",
    "            #if i > 1000:\n",
    "            #    break\n",
    "\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8a22d80-188d-40cb-8112-b1d26fc6550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_load = training_load.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66371f78-6307-4678-9245-6fc5ad20c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_student = train_student.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f5aaa5f-329f-48a1-a7c4-47771e5fe9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, loss 0.0004907820839434862 eval 0.00043807277688756585\n",
      "batch 200, loss 0.019613170996308327 eval 0.018149105831980705\n",
      "batch 400, loss 0.01963702403008938 eval 0.02119535580277443\n",
      "batch 600, loss 0.018109722062945366 eval 0.021934837102890015\n",
      "batch 800, loss 0.01724439486861229 eval 0.01932045817375183\n",
      "batch 1000, loss 0.018242664635181427 eval 0.017968708649277687\n",
      "batch 1200, loss 0.0208011232316494 eval 0.022280286997556686\n",
      "batch 1400, loss 0.018404340371489525 eval 0.03440466150641441\n",
      "batch 1600, loss 0.01849256455898285 eval 0.020981909707188606\n",
      "batch 1800, loss 0.017888443544507027 eval 0.015578248538076878\n",
      "batch 2000, loss 0.016972998157143593 eval 0.015787195414304733\n",
      "batch 2200, loss 0.024909039959311485 eval 0.01773681677877903\n",
      "batch 2400, loss 0.022564906626939774 eval 0.0151264863088727\n",
      "batch 2600, loss 0.018110841512680054 eval 0.01627918891608715\n",
      "batch 2800, loss 0.015825821086764336 eval 0.02474088780581951\n",
      "batch 3000, loss 0.014988021925091743 eval 0.02432212606072426\n",
      "batch 3200, loss 0.014770367182791233 eval 0.01578155905008316\n",
      "batch 3400, loss 0.014168580062687397 eval 0.016827547922730446\n",
      "batch 3600, loss 0.017313277348876 eval 0.017761975526809692\n",
      "batch 3800, loss 0.02206195704638958 eval 0.014182066544890404\n",
      "batch 4000, loss 0.026723666116595268 eval 0.014173786155879498\n",
      "batch 4200, loss 0.025206144899129868 eval 0.01689959317445755\n",
      "batch 4400, loss 0.02472168207168579 eval 0.02175029180943966\n",
      "batch 4600, loss 0.023622281849384308 eval 0.016714077442884445\n",
      "batch 4800, loss 0.022923672571778297 eval 0.017138278111815453\n",
      "batch 5000, loss 0.02287578582763672 eval 0.01823873072862625\n",
      "batch 5200, loss 0.022689010947942734 eval 0.01501542143523693\n",
      "batch 5400, loss 0.021987292915582657 eval 0.014125542715191841\n",
      "batch 5600, loss 0.02153102681040764 eval 0.013620906509459019\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf9d27b8-6751-4b9f-9ff5-da151fb93f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, loss 0.00035550809116102755 eval 0.00032193385413847864\n",
      "batch 200, loss 0.014944372698664665 eval 0.01401171088218689\n",
      "batch 400, loss 0.014824832789599895 eval 0.01503280084580183\n",
      "batch 600, loss 0.013616046868264675 eval 0.015749184414744377\n",
      "batch 800, loss 0.013031495735049248 eval 0.014278181828558445\n",
      "batch 1000, loss 0.01395456399768591 eval 0.013267138972878456\n",
      "batch 1200, loss 0.01468138862401247 eval 0.013175159692764282\n",
      "batch 1400, loss 0.013570351526141167 eval 0.02006489224731922\n",
      "batch 1600, loss 0.013734910637140274 eval 0.014463028870522976\n",
      "batch 1800, loss 0.013555537909269333 eval 0.012185883708298206\n",
      "batch 2000, loss 0.013131998479366302 eval 0.01281646080315113\n",
      "batch 2200, loss 0.018088599666953087 eval 0.01452877838164568\n",
      "batch 2400, loss 0.01717035472393036 eval 0.01251817587763071\n",
      "batch 2600, loss 0.01280650682747364 eval 0.01234343834221363\n",
      "batch 2800, loss 0.011662740260362625 eval 0.017373552545905113\n",
      "batch 3000, loss 0.011339524760842323 eval 0.016870437189936638\n",
      "batch 3200, loss 0.011362596414983273 eval 0.012189787812530994\n",
      "batch 3400, loss 0.011057487688958645 eval 0.01323885191231966\n",
      "batch 3600, loss 0.012620923109352589 eval 0.0147743821144104\n",
      "batch 3800, loss 0.01587173342704773 eval 0.012319670990109444\n",
      "batch 4000, loss 0.019265972077846527 eval 0.011977673508226871\n",
      "batch 4200, loss 0.01871727965772152 eval 0.013704081065952778\n",
      "batch 4400, loss 0.018401876091957092 eval 0.017002908512949944\n",
      "batch 4600, loss 0.017968807369470596 eval 0.012481416575610638\n",
      "batch 4800, loss 0.017541898414492607 eval 0.013158942572772503\n",
      "batch 5000, loss 0.017672615125775337 eval 0.01451313029974699\n",
      "batch 5200, loss 0.01786273717880249 eval 0.013052141293883324\n",
      "batch 5400, loss 0.017233772203326225 eval 0.012360088527202606\n",
      "batch 5600, loss 0.01718219742178917 eval 0.011675648391246796\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7063fd74-bfa7-40bd-a03c-12ca3fa1e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_student,\"myTextEmbeddingStudent.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bc6566d-82c9-4cf6-b416-cf78f13c69e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0889, 0.0290, 0.1779, 0.0552, 0.1240, 0.0832, 0.0954, 0.1503, 0.1411,\n",
      "        0.1218, 0.1133, 0.1743, 0.2627, 0.1597, 0.0803, 0.1733, 0.0684, 0.0305,\n",
      "        0.0641, 0.0711, 0.0875, 0.1424, 0.0534, 0.2224, 0.0571, 0.1333, 0.0841,\n",
      "        0.1107, 0.3379, 0.3598, 0.2315, 0.2541, 0.4290, 0.3136, 0.6903, 0.6348,\n",
      "        0.1901, 0.2954, 0.3188, 0.2644, 0.2233, 0.1063, 0.4486, 0.3006, 0.3250,\n",
      "        0.2148, 0.3080, 0.2658, 0.1342, 0.1948], device='cuda:0',\n",
      "       grad_fn=<DiagonalBackward0>)\n",
      "[tensor(0.6903, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.6348, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.4486, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The spinal cord, which directly interacts with somatic functions below the head, can be considered a caudal extension of the myelencephalon enclosed inside the vertebral column.',\n",
       " 'Together, the brain and spinal cord constitute the central nervous system in all vertebrates.',\n",
       " 'Some basic types of responsiveness such as reflexes can be mediated by the spinal cord or peripheral ganglia, but sophisticated purposeful control of behavior based on complex sensory input requires the information integrating capabilities of a centralized brain.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teacher inference\n",
    "# create the embedding vector database\n",
    "chunk_emb = generate_chunk_emb(m, chunk_data)\n",
    "# search\n",
    "search_document(\"what is spinal cord?\", chunk_data, chunk_emb, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "846277f3-4709-495d-ae9e-1243df3abe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_load = None\n",
    "m = None\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded9fb00-d520-4902-9fdd-2876e4cc7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model=torch.load(\"myTextEmbeddingStudent.pt\").student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fa1f02-ee4d-4ca3-aeb6-559fbf381993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0844,  0.0648,  0.1888,  0.0493,  0.2704,  0.1194,  0.0381,  0.1138,\n",
      "         0.1688,  0.1430,  0.1262,  0.1880,  0.3322,  0.1405, -0.0024,  0.0807,\n",
      "         0.0432,  0.0545,  0.0152,  0.0867,  0.0788,  0.1399,  0.1050,  0.1426,\n",
      "         0.0207,  0.1594,  0.0584,  0.0312,  0.2874,  0.2799,  0.2607,  0.2590,\n",
      "         0.4339,  0.2508,  0.5772,  0.6338,  0.1728,  0.2667,  0.2142,  0.2646,\n",
      "         0.2389,  0.0480,  0.3895,  0.1975,  0.2808,  0.1547,  0.2042,  0.2285,\n",
      "         0.0997,  0.1588], device='cuda:0', grad_fn=<DiagonalBackward0>)\n",
      "[tensor(0.6338, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.5772, device='cuda:0', grad_fn=<SelectBackward0>), tensor(0.4339, device='cuda:0', grad_fn=<SelectBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Together, the brain and spinal cord constitute the central nervous system in all vertebrates.',\n",
       " 'The spinal cord, which directly interacts with somatic functions below the head, can be considered a caudal extension of the myelencephalon enclosed inside the vertebral column.',\n",
       " 'While invertebrate brains arise from paired segmental ganglia (each of which is only responsible for the respective body segment) of the ventral nerve cord, vertebrate brains develop axially from the midline dorsal nerve cord as a vesicular enlargement at the rostral end of the neural tube, with centralized control over all body segments.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# student inference\n",
    "# create the embedding vector database\n",
    "chunk_emb = generate_chunk_emb(student_model, chunk_data)\n",
    "# search\n",
    "search_document(\"what is spinal cord?\", chunk_data, chunk_emb, student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152038a0-9236-4e3a-ae9f-0da9f1af4c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
