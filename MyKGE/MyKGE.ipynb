{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b4e13c-4355-4dc0-a568-5b4f42d90595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TwHIN embeddings (projects/twhin) https://arxiv.org/abs/2202.05387\n",
    "# https://github.com/twitter/the-algorithm-ml\n",
    "# https://en.wikipedia.org/wiki/Knowledge_graph_embedding\n",
    "\n",
    "# Dataset\n",
    "# https://huggingface.co/datasets/Twitter/TwitterFaveGraph\n",
    "# https://stackoverflow.com/questions/25962114/how-do-i-read-a-large-csv-file-with-pandas\n",
    "\n",
    "# TorchRec\n",
    "# https://github.com/pytorch/torchrec/blob/main/Torchrec_Introduction.ipynb\n",
    "\n",
    "# venv setup https://github.com/twitter/the-algorithm-ml/blob/main/images/init_venv.sh\n",
    "# https://stackoverflow.com/questions/42449814/running-jupyter-notebook-in-a-virtualenv-installed-sklearn-module-not-available\n",
    "\n",
    "# loss\n",
    "# https://zhang-yang.medium.com/how-is-pytorchs-binary-cross-entropy-with-logits-function-related-to-sigmoid-and-d3bd8fb080e7\n",
    "# https://medium.com/dejunhuang/learning-day-57-practical-5-loss-function-crossentropyloss-vs-bceloss-in-pytorch-softmax-vs-bd866c8a0d23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1b7314-9091-4a1c-bd0b-44fb431ca7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torchrec\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchrec import EmbeddingBagConfig, EmbeddingBagCollection\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.distributed as dist\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "dist.init_process_group(backend=\"nccl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2293323-def7-47c0-929a-2f9e15468f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKGE(nn.Module):\n",
    "    def __init__(self, embedding_dim = 4, num_features = 2, feature_names=['user', 'tweet'], num_embeddings=[424_241, 72_543], num_relations = 4, in_batch_negatives=10, device = \"cpu\"):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.in_batch_negatives = in_batch_negatives\n",
    "        self.num_relations = num_relations\n",
    "        self.feature_names = feature_names\n",
    "        self.device = device\n",
    "        \n",
    "        tables = []\n",
    "\n",
    "        for i in range(num_features):\n",
    "            tables.append(\n",
    "                EmbeddingBagConfig(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    feature_names=[feature_names[i]],  # restricted to 1 feature per table for now\n",
    "                    name=feature_names[i],\n",
    "                    num_embeddings=num_embeddings[i],\n",
    "                    pooling=torchrec.PoolingType.SUM,\n",
    "                )\n",
    "            )        \n",
    "\n",
    "        # embedding for features\n",
    "        self.ebc = EmbeddingBagCollection(\n",
    "          #device=\"meta\",\n",
    "          device = device,\n",
    "          tables=tables,\n",
    "        )\n",
    "\n",
    "        # embedding for relation (translation)\n",
    "        self.relation_embedding = nn.Embedding(num_relations, embedding_dim)\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, users, tweets, rels):\n",
    "        batch_size = users.shape[0]\n",
    "        mb = torchrec.KeyedJaggedTensor(\n",
    "            keys = self.feature_names,\n",
    "            values = torch.concat([user, tweet]).to(self.device),\n",
    "            lengths = torch.tensor([1], dtype=torch.int64).repeat(batch_size*2).to(self.device), # user batch size + tweet batch size\n",
    "        )        \n",
    "        \n",
    "        x = self.ebc(mb.to(device)).values() # B * 2D\n",
    "        x = x.reshape(batch_size, 2, self.embedding_dim) #  B * 2 * D\n",
    "        trans_embs = self.relation_embedding(rels) # B * D\n",
    "        \n",
    "        # translation\n",
    "        translated = x[:, 1, :] + trans_embs\n",
    "\n",
    "        # negative sampling\n",
    "        negs = []\n",
    "        if self.in_batch_negatives:\n",
    "            for relation in range(self.num_relations):\n",
    "                rel_mask = rels == relation\n",
    "                rel_count = rel_mask.sum()\n",
    "\n",
    "                if not rel_count:\n",
    "                  continue        \n",
    "\n",
    "                # R x D\n",
    "                lhs_matrix = x[rel_mask, 0, :]\n",
    "                rhs_matrix = x[rel_mask, 1, :]\n",
    "\n",
    "                lhs_perm = torch.randperm(lhs_matrix.shape[0])\n",
    "                # repeat until we have enough negatives\n",
    "                lhs_perm = lhs_perm.repeat(math.ceil(float(self.in_batch_negatives) / rel_count))\n",
    "                lhs_indices = lhs_perm[: self.in_batch_negatives]\n",
    "                sampled_lhs = lhs_matrix[lhs_indices]\n",
    "        \n",
    "                rhs_perm = torch.randperm(rhs_matrix.shape[0])\n",
    "                # repeat until we have enough negatives\n",
    "                rhs_perm = rhs_perm.repeat(math.ceil(float(self.in_batch_negatives) / rel_count))\n",
    "                rhs_indices = rhs_perm[: self.in_batch_negatives]\n",
    "                sampled_rhs = rhs_matrix[rhs_indices]\n",
    "        \n",
    "                # RS\n",
    "                negs_rhs = torch.flatten(torch.matmul(lhs_matrix, sampled_rhs.t()))\n",
    "                negs_lhs = torch.flatten(torch.matmul(rhs_matrix, sampled_lhs.t()))\n",
    "        \n",
    "                negs.append(negs_lhs)\n",
    "                negs.append(negs_rhs)   \n",
    "\n",
    "        # dot product for positives' scoring\n",
    "        x = (x[:, 0, :] * translated).sum(-1)\n",
    "\n",
    "        # concat positives and negatives\n",
    "        x = torch.cat([x, *negs])        \n",
    "\n",
    "        return {\n",
    "          \"logits\": x,\n",
    "          \"probabilities\": torch.sigmoid(x),\n",
    "        }        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a40752-bb25-4fd3-aa00-bb7fac35c1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_index</th>\n",
       "      <th>tweet_index</th>\n",
       "      <th>time_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2664563</td>\n",
       "      <td>4656426</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9109889</td>\n",
       "      <td>3354941</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10473449</td>\n",
       "      <td>4994572</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4288842</td>\n",
       "      <td>5859769</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6032357</td>\n",
       "      <td>6472618</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102395</th>\n",
       "      <td>11791325</td>\n",
       "      <td>3499381</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102396</th>\n",
       "      <td>7222675</td>\n",
       "      <td>2559397</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102397</th>\n",
       "      <td>6612248</td>\n",
       "      <td>1656162</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102398</th>\n",
       "      <td>5138976</td>\n",
       "      <td>5782149</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102399</th>\n",
       "      <td>9710834</td>\n",
       "      <td>2472080</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_index  tweet_index  time_chunk\n",
       "0          2664563      4656426         134\n",
       "1          9109889      3354941          32\n",
       "2         10473449      4994572          31\n",
       "3          4288842      5859769         133\n",
       "4          6032357      6472618          10\n",
       "...            ...          ...         ...\n",
       "102395    11791325      3499381         176\n",
       "102396     7222675      2559397         110\n",
       "102397     6612248      1656162         104\n",
       "102398     5138976      5782149         102\n",
       "102399     9710834      2472080         127\n",
       "\n",
       "[102400 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/Twitter/TwitterFaveGraph/blob/main/TwitterFaveGraph.csv.zip\n",
    "filename = \"./TwitterFaveGraph.csv\"\n",
    "df = pd.read_csv(filename, nrows=1024*100)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb14b30-1b25-42a2-bbe5-d65fe022f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterFaveGraphDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_index_data = torch.tensor(int(self.df[\"user_index\"].iloc[idx]))\n",
    "        tweet_index_data = torch.tensor(int(self.df[\"tweet_index\"].iloc[idx]))\n",
    "\n",
    "        return user_index_data, tweet_index_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c468e15c-596b-4f79-a022-129f85a18d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4288842), tensor(5859769))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.sample(frac=0.8,random_state=200)\n",
    "df_test = df.drop(df_train.index)\n",
    "dataset_train = TwitterFaveGraphDataset(df_train)\n",
    "dataset_test = TwitterFaveGraphDataset(df_test)\n",
    "dataset_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c37af06-c631-42ec-b919-42a812238cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size = 512, shuffle = True)\n",
    "dataloader_test = DataLoader(dataset_train, batch_size = 512, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba268321-0089-4bd0-8e9e-bf60d1ee3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, tweet = next(iter(dataloader_train))\n",
    "#user, tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a483e207-b3a5-4e8b-9e9a-5147bb8c4b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6761642"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet_index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab88db3e-661e-442c-be60-b4f223ba2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "#device = \"cpu\"\n",
    "model = MyKGE(num_embeddings=[int(df.user_index.max()+1), int(df.tweet_index.max()+1)])\n",
    "#model = torchrec.distributed.DistributedModelParallel(model, device=torch.device(\"cuda\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "179ea726-1fa3-4255-aabf-97180d78aaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchrec.sparse.jagged_tensor.KeyedJaggedTensor at 0x7f4d745f91c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = torchrec.KeyedJaggedTensor(\n",
    "    keys = [\"user\", \"tweet\"],\n",
    "    values = torch.concat([user, tweet]).to(device),\n",
    "    lengths = torch.tensor([1], dtype=torch.int64).repeat(user.shape[0]*2).to(device),\n",
    ")\n",
    "\n",
    "mb.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a65b32b-983f-483f-97d9-45293b284189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (user): EmbeddingBag(13130632, 4, mode=sum)\n",
       "  (tweet): EmbeddingBag(6761643, 4, mode=sum)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ebc.embedding_bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "048d7366-6b70-4d42-8de6-ae2e21a0df0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingBag(13130632, 4, mode=sum)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ebc.embedding_bags['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f931002-8519-4cec-b4dc-f672b088948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4515,  0.3983, -0.4965,  ..., -0.2964,  1.3926, -0.7841],\n",
       "        [ 0.1097, -1.4804,  0.7915,  ..., -0.0192,  0.1354,  0.0383],\n",
       "        [-2.1182, -1.8855,  0.6606,  ...,  0.0640, -0.7168, -0.8143],\n",
       "        ...,\n",
       "        [-0.5152, -0.4280,  0.0953,  ...,  0.8195, -0.2280, -0.0336],\n",
       "        [ 0.6786, -1.8344, -1.0917,  ..., -1.1620, -1.2750, -1.1539],\n",
       "        [-0.3536,  0.5567, -0.5723,  ..., -1.5122,  0.3058,  2.4866]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ebc(mb).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0dcced0-fb2b-4b8e-8cec-cbcdf4feca47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': tensor([[-0.4515,  0.3983, -0.4965, -2.0446],\n",
       "         [ 0.1097, -1.4804,  0.7915, -1.2557],\n",
       "         [-2.1182, -1.8855,  0.6606,  1.2509],\n",
       "         ...,\n",
       "         [-0.5152, -0.4280,  0.0953,  1.8395],\n",
       "         [ 0.6786, -1.8344, -1.0917, -0.0861],\n",
       "         [-0.3536,  0.5567, -0.5723, -0.1013]], device='cuda:0',\n",
       "        grad_fn=<SplitWithSizesBackward0>),\n",
       " 'tweet': tensor([[ 0.1382, -0.2964,  1.3926, -0.7841],\n",
       "         [ 0.2004, -0.0192,  0.1354,  0.0383],\n",
       "         [-0.2875,  0.0640, -0.7168, -0.8143],\n",
       "         ...,\n",
       "         [-1.0028,  0.8195, -0.2280, -0.0336],\n",
       "         [ 0.1024, -1.1620, -1.2750, -1.1539],\n",
       "         [-1.2999, -1.5122,  0.3058,  2.4866]], device='cuda:0',\n",
       "        grad_fn=<SplitWithSizesBackward0>)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ebc(mb).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a506554-8459-4e6a-aad1-7bedebaab272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embeddings tensor([[-0.4515,  0.3983, -0.4965, -2.0446],\n",
      "        [ 0.1097, -1.4804,  0.7915, -1.2557],\n",
      "        [-2.1182, -1.8855,  0.6606,  1.2509],\n",
      "        ...,\n",
      "        [-0.5152, -0.4280,  0.0953,  1.8395],\n",
      "        [ 0.6786, -1.8344, -1.0917, -0.0861],\n",
      "        [-0.3536,  0.5567, -0.5723, -0.1013]], device='cuda:0',\n",
      "       grad_fn=<SplitWithSizesBackward0>)\n",
      "tweet embeddings tensor([[ 0.1382, -0.2964,  1.3926, -0.7841],\n",
      "        [ 0.2004, -0.0192,  0.1354,  0.0383],\n",
      "        [-0.2875,  0.0640, -0.7168, -0.8143],\n",
      "        ...,\n",
      "        [-1.0028,  0.8195, -0.2280, -0.0336],\n",
      "        [ 0.1024, -1.1620, -1.2750, -1.1539],\n",
      "        [-1.2999, -1.5122,  0.3058,  2.4866]], device='cuda:0',\n",
      "       grad_fn=<SplitWithSizesBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pooled_embeddings = model.ebc(mb).to_dict()\n",
    "print(\"user embeddings\", pooled_embeddings[\"user\"])\n",
    "print(\"tweet embeddings\", pooled_embeddings[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f39a71e0-2502-43ac-9a44-a290e58dbbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4515,  0.3983, -0.4965, -2.0446], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_embeddings[\"user\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eea60fe-33d0-4a37-a4e6-0003204d5d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0\n",
      "train epoch loss: 0.08896548664197326\n",
      "epoch #1\n",
      "train epoch loss: 0.07396449549123645\n",
      "epoch #2\n",
      "train epoch loss: 0.06490082058589905\n",
      "epoch #3\n",
      "train epoch loss: 0.05926096269395202\n",
      "epoch #4\n",
      "train epoch loss: 0.055423598387278616\n",
      "epoch #5\n",
      "train epoch loss: 0.052668127021752296\n",
      "epoch #6\n",
      "train epoch loss: 0.05005531164351851\n",
      "epoch #7\n",
      "train epoch loss: 0.047707011457532644\n",
      "epoch #8\n",
      "train epoch loss: 0.04520940040238201\n",
      "epoch #9\n",
      "train epoch loss: 0.042617363412864505\n"
     ]
    }
   ],
   "source": [
    "lossFunc = F.binary_cross_entropy_with_logits\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_loop():\n",
    "    model.train()\n",
    "    \n",
    "    step = 0\n",
    "    losses = 0\n",
    "    for users, tweets in dataloader_train:\n",
    "        batch_size = users.shape[0]\n",
    "        rels = torch.tensor([0]).repeat(batch_size)\n",
    "        outp = model(users.to(device), tweets.to(device), rels.to(device) )\n",
    "        #print(outp['logits'].shape)\n",
    "\n",
    "        logits = outp['logits']\n",
    "        num_negatives = 2 * batch_size * model.in_batch_negatives\n",
    "        num_positives = batch_size\n",
    "    \n",
    "        neg_weight = float(num_positives) / num_negatives\n",
    "    \n",
    "        labels = torch.cat([torch.ones(num_positives).to(device), torch.ones(num_negatives).to(device)])\n",
    "    \n",
    "        weights = torch.cat(\n",
    "          [torch.ones(num_positives).to(device), (torch.ones(num_negatives) * neg_weight).to(device)]\n",
    "        )\n",
    "       \n",
    "        loss = lossFunc(logits, labels, weights)\n",
    "        loss.backward()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        step+=1\n",
    "        losses += loss.item()\n",
    "        #if step % 100 == 0:\n",
    "            #print(loss)\n",
    "    print(f\"train epoch loss: {losses/step}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loop():\n",
    "    model.eval()\n",
    "    step = 0\n",
    "    losses = 0\n",
    "    print(f\"eval epoch loss: {losses/step}\")\n",
    "    \n",
    "for i in range(10):\n",
    "    print(f'epoch #{i}')\n",
    "    train_loop()\n",
    "    #eval_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tml_venv",
   "language": "python",
   "name": "tml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
