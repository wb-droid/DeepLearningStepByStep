{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927b55cf-2924-4c1d-863e-2b5debf8b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, Pad\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674f6dc4-aa51-4a93-804e-5c301b56d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_data_train = torchvision.datasets.FashionMNIST(root='./data/', train=True, download=True, transform=transforms.Compose([Pad([2,2,2,2]), ToTensor()]))\n",
    "fashion_data_test = torchvision.datasets.FashionMNIST(root='./data/', train=False, download=True, transform=transforms.Compose([Pad([2,2,2,2]), ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b63728-5ef8-4174-bdef-bc0699cbd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(fashion_data_train, batch_size=64, shuffle=True, num_workers=4)\n",
    "dl_test = torch.utils.data.DataLoader(fashion_data_test, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a076b92a-b7fb-4b19-90ab-a07128b1d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1dfbb7-4134-4f05-be73-5b7ff696fd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dl_train))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a0d43f-202f-4229-ae51-ee312dc8ad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouser\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feab2f274d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(labels_map[y[0].item()])\n",
    "plt.imshow(x[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8b05ab-29c6-4ef2-92bf-1f7836bc083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patch = 16\n",
    "nh = nw = int(n_patch**.5)\n",
    "print(nh, nw)\n",
    "#rearrange(x, 'b c (nh ph) (nw pw) -> b (nh nw) (c ph pw)', nh=nh, nw=nw)\n",
    "x1 = rearrange(x, 'b c (nh ph) (nw pw) -> b nh nw (c ph pw)', nh=nh, nw=nw)\n",
    "x2 = rearrange(x1, 'b nh nw d -> b (nh nw) d', nh=nh, nw=nw).shape\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684f901b-72e3-41b5-b826-ebd506879cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec686d00-85cc-4f36-aef8-cd8c476c379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_dummy(nn.Module):\n",
    "    def __init__(self, dim, mlp_hidden_dim=4098, attention_heads=8, depth=2 ):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        \n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, dim, n_classes = len(labels_map), device = device, depth=5):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size #height == width\n",
    "        self.patch_size = patch_size #height == width\n",
    "        self.dim = dim # dim of latent space for each patch\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.nh = self.nw = image_size // patch_size \n",
    "        self.n_patches = self.nh * self.nw # number or patches, i.e. NLP's seq len\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(self.patch_size**2)\n",
    "        self.ln = nn.Linear(self.patch_size**2, dim)\n",
    "        self.layernorm2 = nn.LayerNorm(dim)\n",
    "        self.pos_encoding = nn.Embedding(self.n_patches, self.dim)\n",
    "        self.transformer = Transformer(dim=self.dim, depth=depth)\n",
    "\n",
    "\n",
    "        #self.proj = nn.Linear(self.dim * self.n_patches, self.n_classes)\n",
    "        self.proj = nn.Linear(self.dim, self.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # rearrange 'b c (nh ph) (nw pw) -> b nh nw (c ph pw)'\n",
    "        x = rearrange(x, 'b c (nh ph) (nw pw) -> b nh nw (c ph pw)', nh=self.nh, nw=self.nw)\n",
    "        # rearrange 'b nh nw d -> b (nh nw) d'\n",
    "        x = rearrange(x, 'b nh nw d -> b (nh nw) d')\n",
    "\n",
    "        \n",
    "        x = self.layernorm1(x)        \n",
    "        x = self.ln(x) #(b n_patches patch_size*patch_size) -> (b n_patches dim)\n",
    "        x = self.layernorm2(x)\n",
    "\n",
    "        pos = self.pos_encoding(torch.arange(0, self.n_patches).to(device))\n",
    "\n",
    "        x = x + pos\n",
    "        \n",
    "        x = self.transformer(x)\n",
    "\n",
    "        #x = self.proj(x.view(x.shape[0],-1))\n",
    "        x = self.proj(x.mean(dim=1))\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545f89e9-0acc-4b32-91dd-61d55194d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MyViT(image_size=32, patch_size=8, dim=1024).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad78ebd6-ddaa-4bbc-9806-765e557d0d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lossFunc = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#lr_scheduler = \n",
    "\n",
    "def train(epoches):\n",
    "    for _ in range(epoches):\n",
    "        step = 0\n",
    "        losses = 0\n",
    "        model.train()\n",
    "        for data_train, label_train in dl_train:\n",
    "            data_train = (data_train-0.5).to(device)\n",
    "            label_train = label_train.to(device)\n",
    "            logits = model(data_train)\n",
    "            loss = lossFunc(logits, label_train)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "            step+=1\n",
    "            if step % 100 == 0:\n",
    "                print(f\"loss is {losses/100}\")\n",
    "                losses = 0\n",
    "            losses += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            data_test, label_test = next(iter(dl_test))\n",
    "            data_test = (data_test-0.5).to(device)\n",
    "            label_test = label_test.to(device)\n",
    "            logits = model(data_test)\n",
    "            accuracy = (logits.argmax(dim=-1) == label_test).sum()/label_test.shape[0]\n",
    "            print(f\"accuracy is {accuracy}\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab13201-e72d-4ee4-bef4-6151a7f4ee94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be6a937-6e38-4808-a19a-eb4bd47346a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, dim, mlp_hidden_dim=4096, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.proj1 = nn.Linear(dim, mlp_hidden_dim)\n",
    "        self.proj2 = nn.Linear(mlp_hidden_dim, dim)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        x = self.proj1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)        \n",
    "        x = self.proj2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, dim, attention_heads = 8, depth=2, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.attention_heads = attention_heads\n",
    "        \n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        self.proj = nn.Linear(dim, 3*dim)\n",
    "        self.attention = nn.Softmax(dim = -1)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layernorm(x)\n",
    "        q,k,v = self.proj(x).chunk(3, dim=-1)\n",
    "        \n",
    "        # rearrange to b, num_heads, seq, head_size\n",
    "        q = rearrange(q, 'b s (nh hs) -> b nh s hs', nh = self.attention_heads)\n",
    "        k = rearrange(k, 'b s (nh hs) -> b nh hs s', nh = self.attention_heads)\n",
    "        v = rearrange(v, 'b s (nh hs) -> b nh s hs', nh = self.attention_heads)\n",
    "\n",
    "        # attention q@kT\n",
    "        x = q@k\n",
    "\n",
    "        # scale\n",
    "        x = x * (k.shape[-1] ** -0.5)\n",
    "\n",
    "        # attention mask not needed\n",
    "        #x = x.mask_fill(torch.ones((1,1, k.shape[-1], k.shape[-1])).tril())\n",
    "\n",
    "        # attention softmax\n",
    "        x = self.attention(x)\n",
    "\n",
    "        # drop out\n",
    "        x = self.drop(x)\n",
    "\n",
    "        # attention q@kT@v\n",
    "        x = x@v\n",
    "\n",
    "        # rearrange to b, seq, (num_heads, head_size)\n",
    "        x = rearrange(x, 'b nh s hs -> b s (nh hs)', nh = self.attention_heads)\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, mlp_hidden_dim=4098, attention_heads=8, depth=5 ):\n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "        #self.net = nn.Sequential(*([AttentionBlock(dim=dim), MLPBlock(dim=dim)] * depth))\n",
    "        #self.net = nn.Sequential(*([MLPBlock(dim=dim)] * depth))\n",
    "        self.net = nn.ModuleList([AttentionBlock(dim=dim), MLPBlock(dim=dim)] * depth)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        for m in self.net:\n",
    "            x = x + m(x)\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "392f6c0f-4bf9-4f3b-84fe-bdd7094b5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyViT(image_size=32, patch_size=4, dim=256, depth=2).to(device)\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34fa750f-1f56-499b-8e76-5c629dd07e48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.1556322646141053\n",
      "loss is 0.6365352895855904\n",
      "loss is 0.5412473030388355\n",
      "loss is 0.5158590659499168\n",
      "loss is 0.4675754211843014\n",
      "loss is 0.447547090947628\n",
      "loss is 0.45171445965766904\n",
      "loss is 0.39996898457407953\n",
      "loss is 0.400007429420948\n",
      "accuracy is 0.8515625\n",
      "loss is 0.3653336361050606\n",
      "loss is 0.3598775805532932\n",
      "loss is 0.3701637613773346\n",
      "loss is 0.373639519661665\n",
      "loss is 0.35503422901034354\n",
      "loss is 0.36261730805039405\n",
      "loss is 0.3571916051208973\n",
      "loss is 0.35216414242982863\n",
      "loss is 0.34049608260393144\n",
      "accuracy is 0.875\n",
      "loss is 0.30841057196259497\n",
      "loss is 0.29692624680697915\n",
      "loss is 0.3094658311456442\n",
      "loss is 0.32230329111218453\n",
      "loss is 0.3086127416789532\n",
      "loss is 0.31288267724215985\n",
      "loss is 0.3075242643803358\n",
      "loss is 0.3006883884221315\n",
      "loss is 0.301412169188261\n",
      "accuracy is 0.8515625\n",
      "loss is 0.259475910961628\n",
      "loss is 0.2638974793255329\n",
      "loss is 0.26720745969563725\n",
      "loss is 0.266714890897274\n",
      "loss is 0.28658212646842\n",
      "loss is 0.28004994966089725\n",
      "loss is 0.2748061515390873\n",
      "loss is 0.28585870668292046\n",
      "loss is 0.28864468917250635\n",
      "accuracy is 0.8828125\n",
      "loss is 0.2342733258754015\n",
      "loss is 0.24188248217105865\n",
      "loss is 0.2319269921630621\n",
      "loss is 0.257478566467762\n",
      "loss is 0.262670191898942\n",
      "loss is 0.25887869007885456\n",
      "loss is 0.2650331585854292\n",
      "loss is 0.25832315735518935\n",
      "loss is 0.25389482609927655\n",
      "accuracy is 0.90625\n",
      "loss is 0.19620724927634\n",
      "loss is 0.210416329652071\n",
      "loss is 0.22572848305106163\n",
      "loss is 0.23841935843229295\n",
      "loss is 0.24006599642336368\n",
      "loss is 0.23131430231034755\n",
      "loss is 0.22267721869051457\n",
      "loss is 0.24399939976632595\n",
      "loss is 0.22497396927326918\n",
      "accuracy is 0.8671875\n",
      "loss is 0.18018791548907756\n",
      "loss is 0.19839392967522143\n",
      "loss is 0.1767152964323759\n",
      "loss is 0.20421208657324313\n",
      "loss is 0.20689732410013675\n",
      "loss is 0.1943565283343196\n",
      "loss is 0.21437250010669232\n",
      "loss is 0.21672095358371735\n",
      "loss is 0.21544406943023206\n",
      "accuracy is 0.921875\n",
      "loss is 0.1437764051184058\n",
      "loss is 0.16988517969846725\n",
      "loss is 0.17849438045173882\n",
      "loss is 0.19312465142458676\n",
      "loss is 0.19068162735551597\n",
      "loss is 0.1857167337089777\n",
      "loss is 0.18254911705851554\n",
      "loss is 0.19698794484138488\n",
      "loss is 0.18948060546070336\n",
      "accuracy is 0.890625\n",
      "loss is 0.14414692245423794\n",
      "loss is 0.13907304108142854\n",
      "loss is 0.13893431648612023\n",
      "loss is 0.16558646634221078\n",
      "loss is 0.1791895439848304\n",
      "loss is 0.15299201358109712\n",
      "loss is 0.15374065116047858\n",
      "loss is 0.19717791367322207\n",
      "loss is 0.17612086158245802\n",
      "accuracy is 0.875\n",
      "loss is 0.1179352816939354\n",
      "loss is 0.12771906362846494\n",
      "loss is 0.13257499922066926\n",
      "loss is 0.13060407184064388\n",
      "loss is 0.1379130763746798\n",
      "loss is 0.14549560613930226\n",
      "loss is 0.15854986924678088\n",
      "loss is 0.15823725536465644\n",
      "loss is 0.1559769554808736\n",
      "accuracy is 0.890625\n"
     ]
    }
   ],
   "source": [
    "train(epoches = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5942b8f6-6dff-4307-a456-6ca36d86a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"vit01.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33fb578-000a-4ab9-a29c-5eb74b166fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
